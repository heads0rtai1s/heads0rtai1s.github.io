<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on head spin - the Heads or Tails blog</title>
    <link>/categories/machine-learning/</link>
    <description>Recent content in Machine Learning on head spin - the Heads or Tails blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 03 Oct 2019 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/categories/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>The best of both worlds: R meets Python via reticulate</title>
      <link>/2019/10/03/reticulate-intro/</link>
      <pubDate>Thu, 03 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/10/03/reticulate-intro/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;&lt;em&gt;As far as rivalries go, R vs Python can almost reach the levels of the glory days of Barca vs Madrid, Stones vs Beatles, or Sega vs Nintendo. Almost. Just dare to venture onto Twitter asking which language is best for data science to witness two tightly entrenched camps.&lt;/em&gt; Or at least that’s what seemingly hundreds of Medium articles would like you believe. In reality, beyond some good-natured and occasionally entertaining joshing, the whole debate is rather silly. Because the question itself is wrong. It’s the whole &lt;em&gt;“My kung fu is better than your kung fu”&lt;/em&gt; mindset that completely misses the point.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Because what matters the most is choosing the best tool for the specific job.&lt;/strong&gt; Data challenges can be so diverse that no single language could possibly be best suited to solve them all. It’s like the &lt;a href=&#34;https://en.wikipedia.org/wiki/No_free_lunch_theorem&#34;&gt;no-free-lunch theorem&lt;/a&gt;, only for the tools that build those lunch tools. &lt;em&gt;Which makes it the no-free-kitchen theorem, I suppose … . I shall be working on this analogy.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I argue that data analysis needs to be problem-centric and language-agnostic to tap into its full potential.&lt;/strong&gt; Use whatever language gives you the best equipment to solve your problem. This also prevents you from only having a hammer and treating every problem like a nail. One recent development toward a problem-centric analysis style is the fantastic R package &lt;a href=&#34;https://rstudio.github.io/reticulate/&#34;&gt;reticulate&lt;/a&gt;. This package allows you to mix R and Python code in your data analysis, and to freely pass data between the two languages.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The topic of this blog post will be an introductory example on how to use reticulate.&lt;/strong&gt; We will approach a simple supervised classification problem by first exploring the data with &lt;a href=&#34;https://cran.r-project.org/web/packages/ggplot2/index.html&#34;&gt;ggplot2&lt;/a&gt; plots, then turn to Python’s &lt;a href=&#34;https://scikit-learn.org/stable/&#34;&gt;scikit-learn&lt;/a&gt; for modelling, and finally visualise the results again in R.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note: you need at least RStudio version 1.2 to be able to pass objects between R and Python.&lt;/strong&gt; In addition, as always, here are the required packages:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;libs &amp;lt;- c(&amp;#39;dplyr&amp;#39;, &amp;#39;tidyr&amp;#39;, &amp;#39;stringr&amp;#39;,  # wrangling
          &amp;#39;knitr&amp;#39;,&amp;#39;kableExtra&amp;#39;,         # table styling
          &amp;#39;ggplot2&amp;#39;,&amp;#39;gridExtra&amp;#39;,        # plots
          &amp;#39;viridis&amp;#39;,                    # visuals styling
          &amp;#39;reticulate&amp;#39;)                 # e pluribus unum
invisible(lapply(libs, library, character.only = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’ll be using the famous &lt;a href=&#34;https://en.wikipedia.org/wiki/Iris_flower_data_set&#34;&gt;iris dataset&lt;/a&gt;, which is included in R as part of the &lt;a href=&#34;https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/00Index.html&#34;&gt;datasets&lt;/a&gt; package. Arguably the Hello World of supervised classification problems, this data describes the length and widths of sepals and petals from 3 different species of iris flower. Sepals are the green parts of a flower that first protect and then support the petals. Just in case you too were wondering that. Here are the first couple rows of the data:&lt;/p&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Sepal.Length
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Sepal.Width
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Petal.Length
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Petal.Width
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Species
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
setosa
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
setosa
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
setosa
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.6
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
setosa
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This is a small dataset with 50 instances each per species of iris flower:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;iris %&amp;gt;% 
  count(Species)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 2
##   Species        n
##   &amp;lt;fct&amp;gt;      &amp;lt;int&amp;gt;
## 1 setosa        50
## 2 versicolor    50
## 3 virginica     50&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As a simple example for exploratory data analysis plots we will look at the differences between those 3 species in terms of petal and sepal dimensions. Here, the &lt;a href=&#34;https://cran.r-project.org/web/packages/gridExtra/index.html&#34;&gt;gridExtra&lt;/a&gt; package provides the side-by-side layout:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p1 &amp;lt;- iris %&amp;gt;%  
  ggplot(aes(Petal.Length, Petal.Width, color = Species)) +
  geom_point(size = 4) +
  labs(x = &amp;quot;Petal Length&amp;quot;, y = &amp;quot;Petal Width&amp;quot;) +
  scale_color_viridis(discrete = TRUE, option = &amp;quot;viridis&amp;quot;) +
  theme_bw() +
  theme(legend.position = &amp;quot;none&amp;quot;) +
  ggtitle(&amp;quot;Differences in Iris Species&amp;quot;,
          subtitle = str_c(&amp;quot;Petal and Sepal dimensions vary&amp;quot;,
                           &amp;quot;\n&amp;quot;,
                           &amp;quot;significantly between species&amp;quot;))

p2 &amp;lt;- iris %&amp;gt;% 
  ggplot(aes(Sepal.Length, Sepal.Width, color = Species)) +
  geom_point(size = 4) +
  labs(x = &amp;quot;Sepal Length&amp;quot;, y = &amp;quot;Sepal Width&amp;quot;) +
  scale_color_viridis(discrete = TRUE, option = &amp;quot;viridis&amp;quot;) +
  theme_bw() +
  theme(legend.position = &amp;quot;top&amp;quot;)

grid.arrange(p1, p2, layout_matrix = rbind(c(1,2)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-03-reticulate-intro_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;100%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We find that there are clear clusters for each of the species - especially for setosa and in the petal dimensions. A well-trained classifier should be able to distinguish the three iris species. Now, R is perfectly capable of performing this classification task, but for the sake of the excercise we will turn to Python. Given the popularity of both &lt;code&gt;ggplot2&lt;/code&gt; and &lt;code&gt;scikit-learn&lt;/code&gt;, such a workflow is certainly realistic.&lt;/p&gt;
&lt;p&gt;First, we need to tell R where Python can be found. In &lt;code&gt;reticulate&lt;/code&gt;, the &lt;code&gt;use_python&lt;/code&gt; convenience function takes care of that; all we need is a path to the executable. On a Unix-based system, simply open a terminal and type &lt;code&gt;which python&lt;/code&gt;, then paste the resulting path below. (Or look for &lt;code&gt;python3&lt;/code&gt; instead, but this should really become your default version because for Python 2 the &lt;a href=&#34;https://pythonclock.org&#34;&gt;time is running out&lt;/a&gt;). This is my path:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;use_python(&amp;quot;/usr/bin/python&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now you have the combined power of both R and Python at our fingertips. Use it wisely. In Rmarkdown, you can switch each invidual code chunk to the new language by putting &lt;code&gt;{python}&lt;/code&gt; instead of &lt;code&gt;{r}&lt;/code&gt; into the chunk header.&lt;/p&gt;
&lt;p&gt;So, what’s the easiest way to find out that you’re in Python? You suddenly find yourself starting to count from zero:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;foo = [1, 2, 3]
print(foo[0])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The real advantage, however, is that we can now pass objects from R to Python, and vice versa. To use R objects in Python we access them using the &lt;code&gt;r&lt;/code&gt; object and Python’s &lt;code&gt;.&lt;/code&gt; (dot) notation. For instance, our &lt;code&gt;iris&lt;/code&gt; dataset will be represented by &lt;code&gt;r.iris&lt;/code&gt;, which is a &lt;code&gt;pandas&lt;/code&gt; data frame:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;print(r.iris.loc[:5, [&amp;quot;Sepal.Length&amp;quot;, &amp;quot;Species&amp;quot;]])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Sepal.Length Species
## 0           5.1  setosa
## 1           4.9  setosa
## 2           4.7  setosa
## 3           4.6  setosa
## 4           5.0  setosa
## 5           5.4  setosa&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s prepare a simple &lt;code&gt;scikit-learn&lt;/code&gt; &lt;a href=&#34;https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html&#34;&gt;decision tree classifier&lt;/a&gt;. First, we import the necessary Python libraries:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import pandas
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we split our iris dataset into train vs test samples using the &lt;code&gt;train_test_split&lt;/code&gt; convenience method. Of course, in real life you want to do the train/test split before looking at the data. For the sake of clarity, we choose to explicitely separate out the predictor features vs the species labels:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;train, test = train_test_split(r.iris,
                test_size = 0.4, random_state = 4321)

X = train.drop(&amp;#39;Species&amp;#39;, axis = 1)
y = train.loc[:, &amp;#39;Species&amp;#39;].values
X_test = test.drop(&amp;#39;Species&amp;#39;, axis = 1)
y_test = test.loc[:, &amp;#39;Species&amp;#39;].values&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Those are now Python objects. In order to see and handle them in R you have to use the &lt;code&gt;py$&lt;/code&gt; object. This is the equivalent of the &lt;code&gt;r.&lt;/code&gt; object for working with R variables in Python. For example, because &lt;code&gt;X&lt;/code&gt; is a Python object this R code doesn’t work:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;X %&amp;gt;% head(5)  # doesn&amp;#39;t work&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But this R code does the trick:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;py$X %&amp;gt;% head(5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Sepal.Length Sepal.Width Petal.Length Petal.Width
## 41          4.5         2.3          1.3         0.3
## 16          5.4         3.9          1.3         0.4
## 26          5.0         3.4          1.6         0.4
## 99          5.7         2.8          4.1         1.3
## 5           5.4         3.9          1.7         0.4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let’s switch back to Python code. We wil fit a simple decision tree with &lt;code&gt;sklearn&lt;/code&gt;, apply it to the test set, and visualise the results in R.&lt;/p&gt;
&lt;p&gt;First the fit and prediction. One major advantage of &lt;code&gt;sklearn&lt;/code&gt; is its intuitive and consistent syntax:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;tree = DecisionTreeClassifier(random_state=4321)
clf = tree.fit(X, y)
pred = clf.predict(X_test)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we bring the test predictions back to R and plot some results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;foo &amp;lt;- py$test %&amp;gt;% 
  as_tibble() %&amp;gt;% 
  rename(truth = Species) %&amp;gt;% 
  mutate(predicted = as.factor(py$pred),
         correct = (truth == predicted))

foo %&amp;gt;% 
  head(4) %&amp;gt;% 
  select(-Petal.Length, -Petal.Width) %&amp;gt;% 
  kable() %&amp;gt;% 
  kable_styling()&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Sepal.Length
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Sepal.Width
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
truth
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
predicted
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
correct
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
setosa
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
setosa
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
TRUE
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
setosa
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
setosa
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
TRUE
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
versicolor
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
virginica
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
FALSE
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
virginica
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
virginica
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
TRUE
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p1  &amp;lt;- foo %&amp;gt;% 
  select(-correct) %&amp;gt;% 
  gather(truth, predicted, key = type, value = species) %&amp;gt;% 
  ggplot(aes(Petal.Length, Petal.Width, color = species)) +
  geom_point(data = foo %&amp;gt;% filter(correct == FALSE),
             col = &amp;quot;black&amp;quot;, size = 5) +
  geom_point(size = 2) +
  scale_color_viridis(discrete = TRUE, option = &amp;quot;viridis&amp;quot;) +
  theme_bw() +
  theme(legend.position = &amp;quot;none&amp;quot;,
        text = element_text(size = 16)) +
  facet_wrap(~ type)

p2 &amp;lt;- foo %&amp;gt;% 
  select(-correct) %&amp;gt;% 
  gather(truth, predicted, key = type, value = species) %&amp;gt;% 
  ggplot(aes(Sepal.Length, Sepal.Width, color = species)) +
  geom_point(data = foo %&amp;gt;%
               filter(correct == FALSE),
             col = &amp;quot;black&amp;quot;, size = 5) +
  geom_point(size = 2) +
  scale_color_viridis(discrete = TRUE, option = &amp;quot;viridis&amp;quot;,
              guide = guide_legend(direction = &amp;quot;vertical&amp;quot;)) +
  labs(color = &amp;quot;Species&amp;quot;) +
  theme_bw() +
  theme(legend.position = &amp;quot;bottom&amp;quot;,
        text = element_text(size = 16)) +
  facet_wrap(~ type)

p3 &amp;lt;- foo %&amp;gt;% 
  count(truth, predicted) %&amp;gt;%
  complete(truth, predicted, fill = list(n = 0)) %&amp;gt;% 
  group_by(truth) %&amp;gt;% 
  add_tally(n, name = &amp;quot;true&amp;quot;) %&amp;gt;% 
  mutate(accuracy = n/true * 100) %&amp;gt;% 
  ggplot(aes(truth, predicted, fill = accuracy, label = n)) +
  geom_tile() +
  geom_text(size = 5, color = &amp;quot;grey60&amp;quot;) +
  labs(x = &amp;quot;True Species&amp;quot;, y = &amp;quot;Predicted Species&amp;quot;,
       fill = &amp;quot;Accuracy[%]&amp;quot;) +
  theme_minimal() +
  theme(legend.position = &amp;quot;bottom&amp;quot;,
        text = element_text(size = 16),
        axis.text.x = element_text(
          angle=45, hjust=1, vjust=1.1),
        axis.text.y = element_text(
          angle = 45)) +
  scale_fill_viridis(option = &amp;quot;viridis&amp;quot;) +
  ggtitle(&amp;quot;Classification\nDiagnostics&amp;quot;,
          subtitle = str_c(&amp;quot;Left: confusion matrix&amp;quot;,
            &amp;quot;\n&amp;quot;,
            &amp;quot;Right: misclassified\ninstances&amp;quot;))

grid.arrange(p1, p2, p3,
        layout_matrix = cbind(c(3), c(rep(1,2), rep(2,3))))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-03-reticulate-intro_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This plot layout provides diagnostics for the performance of the classifier:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;On the left, there is a confusion matrix which shows how many test instances of each species were classified as one of the 3 species. The numbers are absolute numbers (remember that this is a small dataset) and the colours encode percentages. For instance, 100% of the 19 setosa instances were correctly classified as setosa. This is the classification accuracy, i.e. the number of true positives. The accuracies for the other two species are pretty high, too; with iris virginica having the lowest proportion of 20 out of 24 instances correctly classified.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;On the right we show two sets of scatter plots that repeat the overview of petal (top) and sepal (bottom) properties from above. The difference is that now we (i) look at the test set only and (ii) plot the true classes on the right and the predicted classes on the left. The colour-coding is the same for both scatter plots (see legend at the bottom). In addition, all the misclassified instances have a black circle around them to highlight their position.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All in all, our simple classifier does a decent job. The setosas are clearly separated from the rest. And disentangling versicolor vs virginica is not trivial. Of course the performance could be improved, but this is not the topic of this post.&lt;/p&gt;
&lt;p&gt;Because more importantly we saw how the &lt;code&gt;reticulate&lt;/code&gt; approach allows us to seamlessly blend together R and Python code to use the combined power of both worlds.&lt;/p&gt;
&lt;p&gt;So, the next time somebody asks you “Python or R?” just reply with a simple “Yes.” (#inclusiveor).&lt;/p&gt;
&lt;p&gt;More resources:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;For running R code in a Jupyter notebook with Python kernel there is the great &lt;a href=&#34;https://rpy2.bitbucket.io&#34;&gt;rpy2 library&lt;/a&gt; combined with Jupyter’s &lt;a href=&#34;https://ipython.readthedocs.io/en/stable/interactive/magics.html&#34;&gt;line or cell magic&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In R, decision trees are implemented via the &lt;a href=&#34;https://cran.r-project.org/web/packages/rpart/index.html&#34;&gt;rpart package&lt;/a&gt;. For general machine learning infrastructure there are the popular &lt;a href=&#34;https://cran.r-project.org/web/packages/caret/index.html&#34;&gt;caret&lt;/a&gt; and the new &lt;a href=&#34;https://cran.r-project.org/web/packages/tidymodels/index.html&#34;&gt;tidymodels&lt;/a&gt;; both led by developer &lt;a href=&#34;https://github.com/topepo&#34;&gt;Max Kuhn&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;For creating visualisations in Python I recommend &lt;a href=&#34;https://seaborn.pydata.org&#34;&gt;seaborn&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
